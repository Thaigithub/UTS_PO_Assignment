{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69ceaa00-6fd0-47fd-b0c5-122224fd772d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autograd import grad, jacobian\n",
    "\n",
    "# import algorithm \n",
    "%run ./Note.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ee5558-5037-4303-a2cf-505c989595fe",
   "metadata": {},
   "source": [
    "# Fletcher-Reeves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f050ee-f0a7-482d-9fae-25c556d7bc39",
   "metadata": {},
   "source": [
    "## Testing using example from Tut 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85610fc6-74ed-4a3c-b295-ec1fb364cfe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " message: Gradient norm below tolerance\n",
       " success: True\n",
       "  status: 0\n",
       "     fun: -2.5\n",
       "       x: [ 5.000e-01  2.000e+00]\n",
       "     nit: 2\n",
       "    nfev: 7\n",
       "    njev: 5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First Qs (page 5)\n",
    "f = lambda x: 2*x[0] + (2*x[0]**2) - (3*x[1])-(2*x[0]*x[1])+(x[1]**2)\n",
    "x1 = np.array([0, 1]) #initial point\n",
    "grad_f = grad(f)\n",
    "fletcher_reeves(f, x1, grad_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c176bc3f-d8e6-4efb-8d30-553b2af76554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " message: Gradient norm below tolerance\n",
       " success: True\n",
       "  status: 0\n",
       "     fun: -0.5\n",
       "       x: [ 0.000e+00  5.000e-01]\n",
       "     nit: 2\n",
       "    nfev: 7\n",
       "    njev: 5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Last Qs (page 7)\n",
    "f = lambda x: x[0] + (x[0]**2) - (2*x[1])-(2*x[0]*x[1])+(2*x[1]**2)\n",
    "x1 = np.array([1, 1]) #initial point\n",
    "grad_f = grad(f)\n",
    "fletcher_reeves(f, x1, grad_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aaf23c9-29c4-4fe8-bf79-e6125a8a421e",
   "metadata": {},
   "source": [
    "# DFP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c89e2c9-35ef-4f92-b4f4-299351a99d0b",
   "metadata": {},
   "source": [
    "## Testing using Tut 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "681809b8-647a-40f0-bccf-0abdd4b64305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Direction (1): [-2.  1.]\n",
      "Grad (1): [ 2. -1.]\n",
      "Alpha (1): 0.22727272727272727\n",
      "x_(1+1): [-0.45454545  0.22727273]\n",
      "s_1 = [-0.45454545  0.22727273], y_1 = [-2.5  0. ]\n",
      "H_1 = [[ 0.18181818 -0.09090909]\n",
      " [-0.09090909  1.04545455]]\n",
      "Direction (2): [2.77555756e-17 1.00000000e+00]\n",
      "Grad (2): [-0.5 -1. ]\n",
      "Alpha (2): 0.5\n",
      "x_(2+1): [-0.45454545  0.72727273]\n",
      " message: Gradient norm below tolerance\n",
      " success: True\n",
      "  status: 0\n",
      "     fun: -0.8181818181818181\n",
      "       x: [-4.545e-01  7.273e-01]\n",
      "     nit: 2\n",
      "    nfev: 7\n",
      "    njev: 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.45454545,  0.72727273])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q1\n",
    "f = lambda x: (2*x[0]) + (3*x[0]**2) - x[1] + (x[0]*x[1]) + (x[1]**2)\n",
    "x1 = np.array([0., 0.]) #initial point\n",
    "H1 = np.array([[1., 0.], [0., 1.]]) #initial H \n",
    "grad_f = grad(f)\n",
    "print(dfp(f, x1, grad_f, H_k=H1))\n",
    "np.array([-5/11,  8/11]) # Actual ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ed9b93d-df45-4615-b43e-bdabcde4edba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Direction (1): [-6. -0.]\n",
      "Grad (1): [6. 0.]\n",
      "Alpha (1): 0.25\n",
      "x_(1+1): [-0.5  0. ]\n",
      "s_1 = [-1.5  0. ], y_1 = [-6.  -1.5]\n",
      "H_1 = [[ 0.30882353 -0.23529412]\n",
      " [-0.23529412  0.94117647]]\n",
      "Direction (2): [-0.35294118  1.41176471]\n",
      "Grad (2): [ 0.  -1.5]\n",
      "Alpha (2): 1.0\n",
      "x_(2+1): [-0.85294118  1.41176471]\n",
      "s_2 = [-0.35294118  1.41176471], y_2 = [0.         2.47058824]\n",
      "H_2 = [[ 0.28571429 -0.14285714]\n",
      " [-0.14285714  0.57142857]]\n",
      "Direction (3): [ 0.13865546 -0.55462185]\n",
      "Grad (3): [0.         0.97058824]\n",
      "Alpha (3): 1.0\n",
      "x_(3+1): [-0.71428571  0.85714286]\n",
      " message: Gradient norm below tolerance\n",
      " success: True\n",
      "  status: 0\n",
      "     fun: -1.1428571428571428\n",
      "       x: [-7.143e-01  8.571e-01]\n",
      "     nit: 3\n",
      "    nfev: 8\n",
      "    njev: 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.71428571,  0.85714286])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q2\n",
    "f = lambda x: (2*x[0]) + (2*x[0]**2) - x[1] + (x[0]*x[1]) + (x[1]**2)\n",
    "x1 = np.array([1.0, 0.]) #initial point\n",
    "H1 = np.array([[1., 0.], [0., 1.]]) #initial H \n",
    "grad_f = grad(f)\n",
    "print(dfp(f, x1, grad_f, H_k=H1))\n",
    "np.array([-5/7,  6/7]) # Actual ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c5987c-ff5e-4ad4-9756-8bfec745884f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
